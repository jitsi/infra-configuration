#!/bin/bash

#set -e
#set -x

#first load our local instance information from Oracle (or cache) (ENVIRONMENT)
. /usr/local/bin/oracle_cache.sh
BUCKET="dump-logs-${ENVIRONMENT}"

JSTAMP=`date +%Y-%m-%d-%H%M`
JHOST=`hostname -s`
TMP_DIR=`mktemp -d /mnt/dump-XXXXX`

if [ -z $ARCH_PATH ]; then
    ARCH_PATH="/mnt/$JHOST-$JSTAMP-dump.tar.gz"
fi

#Run the collect-dump-logs scripts and extract them to the current directory

cp -a /var/log/cloud-init* $TMP_DIR

cp -a /var/log/bootstrap.log $TMP_DIR

cp -a /var/log/postinstall-ansible.log $TMP_DIR

mkdir $TMP_DIR/local

cp -a /var/log/local/* $TMP_DIR/local

cp -a /var/log/syslog $TMP_DIR

echo "HOST: $JHOST, PID: $JPID, STAMP: $JSTAMP, TMP_DIR: $TMP_DIR" > /tmp/boot_dump.log

echo "HOST: $JHOST, PID: $JPID, STAMP: $JSTAMP, TMP_DIR: $TMP_DIR" > $TMP_DIR/boot_dump.log
echo "---------HOST: $JHOST DISK SPACE $JSTAMP---------" > $TMP_DIR/df_dump.log
df -h >> $TMP_DIR/df_dump.log

echo "---------HOST: $JHOST PS OUTPUT $JSTAMP---------" > $TMP_DIR/ps_dump.log
ps auxwww >> $TMP_DIR/ps_dump.log

echo "---------HOST: $JHOST TOP OUTPUT $JSTAMP---------" > $TMP_DIR/top_dump.log
top -n 1 -b >> $TMP_DIR/top_dump.log

echo "---------HOST: $JHOST LSOF OUTPUT $JSTAMP---------" > $TMP_DIR/lsof_dump.log
lsof >> $TMP_DIR/lsof_dump.log

tar zcf $ARCH_PATH -C $TMP_DIR . && echo "Created $ARCH_PATH" >> /tmp/boot_dump.log

[ -d $TMP_DIR ] && rm -r $TMP_DIR

# Assuming OCI CLI is already configured by Ansible
# and instance has write access to this bucket

if [ -z $SKIP_S3_UPLOAD ]; then

    echo "Uploading to Object Storage." >> /tmp/boot_dump.log 2>&1
    OBJECT_NAME=$JHOST-$JSTAMP-$JPID-dump.tar.gz

    $OCI_BIN os object put -bn $BUCKET --name $JHOST-$JSTAMP-$JPID-dump.tar.gz --file $ARCH_PATH --metadata '{"environment":"'"$ENVIRONMENT"'"}'

    echo $OBJECT_NAME >>/tmp/boot_dump.log
else
    echo "Skipping upload to Object Storage." >> /tmp/boot_dump.log
fi